# TFT Trainer Module for TradingJii

This module trains Temporal Fusion Transformer (TFT) models on cryptocurrency volatility datasets. It is designed to scan datasets generated by TradingJii, train one model per pattern category, and save the models for later use in prediction and analysis.

## Features

- Scans dataset directories to find all available symbols, timeframes, and pattern categories
- Trains a separate TFT model for each pattern category with sufficient data
- Applies an 80/20 training/validation split
- Evaluates models with MAPE, MAE, and RMSE metrics
- Creates a comprehensive model registry with metadata
- Generates detailed training logs and summary statistics
- Saves models with metadata for easy retrieval and usage
- Provides detailed logging of the training process
- Supports advanced filtering by symbol and/or timeframe
- Command-line interface with extensive options
- Robust error handling for production environments

## Requirements

The module requires the following Python packages:
- darts (main library for the TFT models)
- torch (PyTorch for deep learning operations)
- pytorch-lightning (used by darts for training)
- pandas (data manipulation)
- numpy (numerical operations)
- colorama (colored console output)

## Installation

1. Install required packages:
```bash
pip install -r requirements.txt
```

## Dataset Structure

The module expects datasets in the following directory structure:
```
datasets/
├── BTC_USDT/
│   ├── 5m/
│   │   ├── cat_0000000.csv
│   │   ├── cat_0000001.csv
│   │   └── ...
│   └── 15m/
│       ├── cat_0000000.csv
│       └── ...
└── ETH_USDT/
    └── ...
```

Each CSV file should contain:
- 7 input columns: `x_1` to `x_7` (volatility values)
- 1 target column: `y` (next-step volatility)
- 1 pattern column (binary encoding of behavior)

## Usage

### Basic usage

```python
from tft_trainer import train_all_tft_models

# Train models for all symbols and timeframes
result = train_all_tft_models(
    dataset_base_dir="datasets",
    model_base_dir="models",
    min_samples=30,
    input_size=7,
    num_epochs=10,
    hidden_size=64,
    n_heads=4,
    dropout=0.1
)

# Print the results
print(result)
```

### Command-line usage

```bash
# Train all models
python tft_trainer.py

# Train only for BTC_USDT
python tft_trainer.py --symbol BTC_USDT

# Train only for BTC_USDT on 5m timeframe
python tft_trainer.py --symbol BTC_USDT --timeframe 5m

# Process all available symbols
python tft_trainer.py --symbol ALL

# Process multiple specific symbols
python tft_trainer.py --symbols BTC_USDT,ETH_USDT,SOL_USDT

# Customize training parameters
python tft_trainer.py --min-samples 50 --epochs 20 --hidden-size 128 --n-heads 8
```

### Running tests

```bash
# Run the test script
python test_tft_trainer.py

# Test with specific symbol and timeframe
python test_tft_trainer.py --symbol ETH_USDT --timeframe 15m
```

## Model Output

Trained models are saved in a mirrored directory structure:
```
models/
├── registry/                         # Contains model registry and logs
│   ├── model_registry.csv            # CSV listing all trained models with metrics
│   ├── model_registry.json           # JSON format of the registry
│   ├── training_summary.json         # Overall training summary statistics
│   └── training_log_20250514_090307.log  # Detailed log file with timestamp
├── BTC_USDT/
│   ├── 5m/
│   │   ├── tft_cat_0000000.pkl
│   │   ├── tft_cat_0000001.pkl
│   │   └── ...
│   └── 15m/
│       ├── tft_cat_0000000.pkl
│       └── ...
└── ETH_USDT/
    └── ...
```

Each `.pkl` file contains a dictionary with:
- `model`: The trained TFT model
- `feature_scaler`: Scaler for input features
- `target_scaler`: Scaler for target values
- `metadata`: Dictionary with training parameters and statistics, including:
  - Model parameters (input_size, num_epochs, hidden_size, n_heads, dropout)
  - Training info (num_samples, train_samples, val_samples, trained_at timestamp)
  - Validation metrics (MAPE, MAE, RMSE) for model evaluation

### Model Registry

The module generates a comprehensive model registry that helps track all trained models:

- `models/registry/model_registry.csv`: CSV file with all trained models and their performance metrics
- `models/registry/model_registry.json`: Same information in JSON format
- `models/registry/training_summary.json`: Overall summary of the training run
- `models/registry/training_log_[timestamp].log`: Detailed log file with information grouped by symbol and timeframe

## Using Trained Models for Prediction

```python
import pickle
import pandas as pd
from darts import TimeSeries

# Load a model package
with open('models/BTC_USDT/5m/tft_cat_0000000.pkl', 'rb') as f:
    model_package = pickle.load(f)

# Extract model and scalers
model = model_package['model']
feature_scaler = model_package['feature_scaler']
target_scaler = model_package['target_scaler']

# Example: prepare new data for prediction
new_data = pd.DataFrame({
    'x_1': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7],
    'x_2': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],
    'x_3': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
    'x_4': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
    'x_5': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1],
    'x_6': [0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2],
    'x_7': [0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3]
})

# Create synthetic time index
new_data['time'] = pd.date_range(start='2023-01-01', periods=len(new_data), freq='H')
new_data.set_index('time', inplace=True)

# Convert to TimeSeries and scale
features_series = TimeSeries.from_dataframe(new_data)
features_scaled = feature_scaler.transform(features_series)

# Make prediction
prediction_scaled = model.predict(n=1, past_covariates=features_scaled)

# Inverse scale the prediction
prediction = target_scaler.inverse_transform(prediction_scaled)
print(f"Predicted next volatility: {prediction.values().item()}")
```

## Error Handling

The module is designed to be fault-tolerant:
- If a dataset has fewer than `min_samples` rows, it is skipped with a warning
- If training fails for a file, the exception is caught, logged, and the process continues
- If output directories don't exist, they are created automatically

## Logging

The module uses the TradingJii logging system with colored output:
- Green for INFO logs
- Yellow for WARNING logs
- Red for ERROR logs

Example log output:
```
[INFO] Training TFT for BTC_USDT (5m), pattern 1010110 — 84 samples
[INFO] Model saved to models/BTC_USDT/5m/tft_cat_1010110.pkl
[WARNING] [SKIP] BTC_USDT (5m), pattern 1111111 — Not enough samples (24 < 30)
